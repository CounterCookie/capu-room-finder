# -*- coding: utf-8 -*-
"""Copy of cap_classes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TGSKuHBgrEzWKV7_fwHJBIdok6wp9ioC

Capilano University Unoccupied Room Finder
---------------------
#### Name: Shayan Heidari
This project is a tool to find available(unoccupied) rooms in Capilano University to use as study spaces.

### Tools used:
* `matplotlib`: Graping the room begin times and end times.
* `requests`: Grabbing data from the portal.
* Chrome devtools to inspect the network requests which are made while searching for classes.
* Visual JSON viewer at [http://jsonviewer.stack.hu](http://jsonviewer.stack.hu/) to make sense of the data we're getting back.


This is achieved by using the guest registration portal. Everything is given to the client via XHR so it was very easy to use the portal as sort of a Frankenstein API.

The building blocks of this project were formed by staring at chrome devtools while gathering class data.

Graphing is simple and it's achieved by using matplot's `vlines`


### Credits:
* "Generate timetable using matplotlib"
    * [https://masudakoji.github.io/2015/05/23/generate-timetable-using-matplotlib/en/](https://masudakoji.github.io/2015/05/23/generate-timetable-using-matplotlib/en/)
    * by Koji Masuda
        * This bit of code was a bit helpful to reflect the x and y ticks. Even though their project was trying to achieve the same thing as me, I simply found it too complicated for this pupose since not much eye candy was required.

## Data Gathering
"""

import requests, json, numpy as np
from pprint import pprint
from dataclasses import dataclass
import matplotlib.pyplot as plt

"""This is used to acquire an http `session` throughout this entire program in order to retain cookies and different session headers.

Using sessions is also recommended for better performance and reduces latency in the intiation of each request.
"""

session = requests.Session()

"""This hardcoded bit is the sort of cryptic date that refers to Spring of 2023.

A better version of this bit would include a list of available terms to look at with their corresponding names and cryptic date.

This declaration is extremely important. As can be seen later.

Maximum term to display, 4 is enough for the past 4 terms.
"""

maxTerms = 4

termURL = \
    f"""https://ssb9s.capilanou.ca:8443/StudentRegistrationSsb/ssb/classSearch/
    getTerms?searchTerm=&offset=1&max={maxTerms}
    """

terms = json.loads( session.get(termURL).text )

"""#### Change here:"""

index = 0

selectTerm = terms[index]['code']

"""Only uses the above. Leave unchanged"""

termData = {'term': selectTerm}

"""### The last term:
Change the above to index [1] if you want the term before it. (eg. Spring 23 instead of Summer 23)
"""

title = terms[index]['description']
print(title)

"""The term `offset` is the offset from the beginning of the class list.

For example, to get the 400th class in a request size of 200, the offset needs to be 200.

This is extremely useful to get every single class within a for loop.
"""

offset = 0

"""Hardcoded and has to stay. The backend gives no indication of hitting the request size limit and simply truncates the output with no error.

The 200 value is a tested limit.
"""

requestSize = 200

"""For some reason, the server only lets our class search come back with full results if we have previously decalred to it, using a post request, what term we're looking for.

This "setting" on the server is then rememberd by using our `JSESSIONID` in the cookies. This is why it's crucial to use http sessions.
"""

session.post('https://ssb9s.capilanou.ca:8443/StudentRegistrationSsb/ssb/term/search?mode=search',
             data=termData)

"""The URL used to acquire results needs the term we're requesting even though we've set it in the previous code block, page offset and request size which are crucial.

Sorting does not matter at all since all the data is structured internally and then graphed.
"""

requestUrl = f"https://ssb9s.capilanou.ca:8443/StudentRegistrationSsb/ssb/searchResults/searchResults?txt_term={termData['term']}&startDatepicker=&endDatepicker=&pageOffset={offset}&pageMaxSize={requestSize}&sortColumn=subjectDescription&sortDirection=asc"

"""Simply making a request to the and storing its reponse in an string format, loading it using the json library to a python dictionary so we can work with it."""

rawData = session.get(requestUrl).text
jsonData = json.loads(rawData)

"""Only the reponse's `data` portion is useful to us."""

data = jsonData['data']

"""If the university changes their registration system, this project can still be prototyped using the static data stored in the samples folder.

**Only uncomment if the http requests fail**
"""

#with open('Data Samples/spring22_200_data', 'r') as f:
#    data = json.loads(f.read())['data']

"""This class was used before realizing the need to use sets instead of sets.

Its usage can be seen in previous commits but it's been replaced for now.

Still very helpful tho.
"""

@dataclass
class Monday:
    roomname:str
    begintime: int
    endtime: int
    # test
    index: int
    # test

    @classmethod
    def room(cls, data, num):
        roomname = data['buildingDescription'] + data['room']
        begintime = data['beginTime']
        endtime = data['endTime']
        #test
        index = num
        #test

        return Monday(roomname, begintime, endtime, index)

"""Function to develop a valid list of rooms with classes taking place on Monday.

The valid entries in the data would have to follow these conditions:
* The `meetingsFaculty` should not be empty, since such entry would be an asynchronous online class.
* the `building` entry inside `meetingsFaculty` should also not be empty and even if it's non empty, it should not be an `ON` or online class. since those are synchronous online classes.

The long list comprehension was my solution to easily filter without many if consi

This compiles a set of classes which is a list of classes, nonrepeating. Crucial to making the graph happen the way I thought of it.




### Attention:
Even though the data is filtered properly here, the dataset still contains small inaccuracies. Some observed inaccuracies were for example, the `building` entry being called "off campus" instead of `ON` or "online".
"""

def roomSearch(data, day):
    c = 0

    monday = []

    roomList = set() # unique room Names. we can tolerate some inaccuracies.

    for i in data:
    #    print(c)
        if (len(i['meetingsFaculty']) != 0) and (len([e for e in [d for d in i['meetingsFaculty']]]) != 0):
            for f in i['meetingsFaculty']:
                if (f['meetingTime']['building'] != None) and (f['meetingTime']['building'] != "ON") :
                    section = f['meetingTime']
                    if section['buildingDescription'] == None or section['room'] == None:
                      continue
                    roomname = (section['buildingDescription'] + section['room'])
                    #print(roomname)

                    # Hardcoded for now just to test the program.
                    if section[day] == True:
                        #monday.append(Monday.room(section, c))
                        roomList.add(roomname)



        # For debugging purposes
        c += 1
    #print(monday)
    #return monday
    return list(roomList)

"""This function is almost the exact same as above but finds the nonrepeating rooms in the dataset and adds a tuple of begin and endtimes to the array within the `roomNHours` dictionary.

This is just to make the data very easy to graph with little code. Given, this is not a perfect solution.

The roomname is currently the full building name just to confirm the program for now. The shortened names such as BR for Birch will be implemented later.
"""

def hourFind(rooms, data):
    c = 0
    roomNHours = {}

    for room in rooms:
        roomNHours[room] = [] # initiate the empty list to be filled with tuples

    for i in data:
    #    print(c)
        for room in rooms:
            if (len(i['meetingsFaculty']) != 0) and (len([e for e in [d for d in i['meetingsFaculty']]]) != 0):
                for f in i['meetingsFaculty']:
                    if (f['meetingTime']['building'] != None) and (f['meetingTime']['building'] != "ON") :
                        section = f['meetingTime']
                        if section['buildingDescription'] == None or section['room'] == None:
                          continue
                        roomname = (section['buildingDescription'] + section['room'])
                        #print(roomname)
                        if (section['buildingDescription'] + section['room']) == room and (section["beginTime"] != None) and section[day] == True :
                            #monday.append(Monday.room(section, c))
                            # Simple math to convert hour:min to floating point to make it
                            # suitable for graphing
                            beginTime = int( section["beginTime"][:2] ) + (int( section["beginTime"][-2:] ) * 100 / 60) / 100
                            endTime = int( section["endTime"][:2] ) + (int( section["endTime"][-2:] ) * 100 / 60) / 100
                            roomNHours[room].append( (beginTime, endTime, ) )




        c += 1
    #print(monday)
    #return monday
    return roomNHours

"""For now, I know that the list of classes has only about 2000 entries but this data is provided to us in the first request. That's what also makes the browser experience possible.

This is a more compact version of the request explained above. This is a prototype for now.
"""

#roomData = roomSearch(data)
dataList = []
for i in range(17):
    requestUrl = f"https://ssb9s.capilanou.ca:8443/StudentRegistrationSsb/ssb/searchResults/searchResults?txt_term={termData['term']}&startDatepicker=&endDatepicker=&pageOffset={offset}&pageMaxSize={requestSize}&sortColumn=subjectDescription&sortDirection=asc"
    data=json.loads(session.get(requestUrl).text)['data']
    for i in data:
        dataList.append(i)
    offset += 200

pprint(dataList[5])

"""### Set the day"""

day = 'thursday'

hours = hourFind( roomSearch( dataList, day ), dataList )

pprint(hours)

"""## Graphing

Set the plot size to 50 by 10, However, for actual graphing of the entire Monday classes. This needs to be set dynamically depending on the room size.

Set font to 8, doesn't need to be set dynamically.

Enable y axis grids to make hours readable.

A one-time operation to set the x ticks so that there's room and entries on the graph for every room.

Set the xtick labels to room names. The main part.

Mirror the X and Y labels so that it's easier to look at the graph. A better revision is needed to divide the graph into subplots for easier viewing. 10 classes on each plot. To be added.

Iterate over and plot every dictionary entry

Save the plot into A pdf file for practical viewing. The file is written to the relative current directory.
"""

fig, ax = plt.subplots(figsize=(200, 10))

plt.rc('font', size=8)

ax.yaxis.grid()
ax.set_yticks( np.arange(7, 23) ) # set hour grid limit.
ax.set_xticks( [i for i in range(1, len(hours)+1 )] )
ax.set_xticklabels( list(hours.keys()) )

# Set axis and title names.
ax.set_ylabel('Time')
ax.set_xlabel('Rooms')
ax.set_title(day)



'''
***************************************************************************************/
*    Title: Generate timetable using matplotlib
*    Author: Koji Masuda
*    Date: 2015
*    Availability: https://masudakoji.github.io/2015/05/23/generate-timetable-using-matplotlib/en/
*
***************************************************************************************/
'''
# ax2=ax.twiny().twinx()
# ax2.set_xticks(ax.get_xticks())
# ax2.set_xticklabels( list(hours.keys()) )
# ax2.set_ylabel('Time')
'''
End of citation
'''


pos = 1
for h in hours:
    for t in hours[h]:
        ax.vlines( pos, t[0], t[1], linewidth=5)
    pos += 1


# Set grid watermark
xMiddle = ( pos / 3 )
yMiddle = 11
ax.text( xMiddle, yMiddle,
        f'{day} {title}',
        fontsize=500,
        alpha=0.2)

# Mark the grid for eyes' sake
for x in np.arange(0.5, pos, 5):
    for y in range(7, 23):
        plt.text(x, y, f'{y}')



plt.savefig(f"{day}.pdf")
